{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis-- Supervised Learning\n",
    "* Created on Mon Sep. 29 2021 by Shangying Wang\n",
    "* Last Modified: April 6, 2023\n",
    "* this code is used for prediction of the phenotypes from the combinatory motifs\n",
    "* This code uses the convolutional neural network and LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras import layers,Sequential\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Average, BatchNormalization, LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D,MaxPool1D, concatenate\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.initializers import RandomNormal,HeNormal,GlorotNormal,HeUniform,LecunNormal,LecunUniform,Orthogonal\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler\n",
    "from itertools import product\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For arrayed data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data from csv file\n",
    "- CSV files available at https://www.science.org/doi/suppl/10.1126/science.abq0225/suppl_file/science.abq0225_data_s1_to_s3.zip\n",
    "- Change schema to match version used in original commits\n",
    "- Change motif values to match those used in original commits (i.e., change 17 to 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(1)\n",
    "train_data=pd.read_csv('science.abq0225_data_s2.csv',encoding= 'unicode_escape',sep=',')\n",
    "test_data=pd.read_csv('science.abq0225_data_s3.csv',encoding= 'unicode_escape',sep=',')\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "rename_dict = {'Initial CAR T Cell Number': 'Cell Number',\n",
    "               'motif i': 'motif',\n",
    "               'motif j': 'motif.1',\n",
    "               'motif k': 'motif.2',\n",
    "               'motif l': 'motif.3',\n",
    "               'motif m': 'motif.4',\n",
    "               'Cytotoxicity (Nalm 6 Survival)': 'Nalm 6 Cytotoxicity',\n",
    "               'Stemness (% IL7Ra+ KLRG1-)': 'IL7RaKLRG1 stemness'}\n",
    "train_data.rename(columns=rename_dict, inplace=True)\n",
    "test_data.rename(columns=rename_dict, inplace=True)\n",
    "train_data.drop([train_data.columns[7]], axis=1, inplace=True)\n",
    "test_data.drop([test_data.columns[7]], axis=1, inplace=True)\n",
    "train_data.replace(17, 14, inplace=True)\n",
    "test_data.replace(17, 14, inplace=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data statistics\n",
    "all_data = pd.concat([test_data, train_data])\n",
    "max_cell=max(all_data['Cell Number'])\n",
    "all_data['Cell Number']=all_data['Cell Number']/max_cell\n",
    "train_data['Cell Number']=train_data['Cell Number']/max_cell\n",
    "test_data['Cell Number']=test_data['Cell Number']/max_cell\n",
    "stats_df = all_data.describe()\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_vals1=all_data['Nalm 6 Cytotoxicity'].skew()\n",
    "skew_vals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_vals2=all_data['IL7RaKLRG1 stemness'].skew()\n",
    "skew_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,20])\n",
    "pheno=['IL7RaKLRG1 stemness']\n",
    "new_data = all_data.copy()\n",
    "pp=0\n",
    "plt.subplot(3,2,1)\n",
    "new_data[pheno[pp]].hist(bins=10)\n",
    "plt.xlabel('value', fontsize=20)\n",
    "plt.ylabel('frequency', fontsize=20)\n",
    "plt.title('before np.log1p', fontsize=20)\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "new_data[pheno[pp]]=new_data[pheno[pp]].apply(np.log1p)\n",
    "new_data[pheno[pp]].hist(bins=10)\n",
    "plt.xlabel('value', fontsize=20)\n",
    "#plt.ylabel('frequency', fontsize=20)\n",
    "plt.title('after np.log1p', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_vals2=new_data['IL7RaKLRG1 stemness'].skew()\n",
    "skew_vals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['IL7RaKLRG1 stemness'] = train_data['IL7RaKLRG1 stemness'].apply(np.log1p)\n",
    "test_data['IL7RaKLRG1 stemness'] = test_data['IL7RaKLRG1 stemness'].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = train_data.describe()\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network for Nalm 6 Cytotoxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_motifs=5\n",
    "num_class=num_class=len(np.unique(new_data.iloc[:,1:(num_motifs+1)]))\n",
    "np.unique(new_data.iloc[:,1:(num_motifs+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y=np.max(new_data['Nalm 6 Cytotoxicity'])\n",
    "max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICN_train, X_train, Y_train = train_data.iloc[:, :1], train_data.iloc[:,1:(num_motifs+1)], train_data['Nalm 6 Cytotoxicity']/max_y\n",
    "ICN_test, X_test, Y_test = test_data.iloc[:, :1], test_data.iloc[:,1:(num_motifs+1)], test_data['Nalm 6 Cytotoxicity']/max_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding for 14 linear motifs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_channel=to_categorical(X_train, num_classes=num_class)\n",
    "X_test_channel=to_categorical(X_test, num_classes=num_class)\n",
    "print(np.shape(X_test_channel)) #3D tensor with shape (batch_size, steps, features/channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = Y_train.describe()\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV--search for the optimal hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.reshape(X_train_channel, [np.shape(X_train_channel)[0], -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to tune the parameters, define deep NN structure as a tuning function\n",
    "def create_model(filters=32, kernel_size=3, LSTM_units=4, dropout_rate1=0.2, fc_nodes=50):\n",
    "    #seperate inputs:\n",
    "    # create model\n",
    "    input_all=Input(shape=(76,),name='input_all')\n",
    "    input1=Lambda(lambda x: x[:,:-1])(input_all)\n",
    "    input_position = tf.keras.layers.Reshape((num_motifs, num_class), input_shape=(75,))(input1)\n",
    "    input_ICN = Lambda(lambda x: tf.expand_dims(x[:,-1],-1))(input_all) # (None,1)\n",
    "                           \n",
    "    x=Conv1D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu', input_shape=(num_motifs, num_class))(1.0*input_position)\n",
    "    x=LSTM(LSTM_units,return_sequences=True, dropout=dropout_rate1)(x)#return_sequences=True,\n",
    "    x = Flatten()(x)\n",
    "    model1 = keras.Model(inputs=input_all, outputs=x)\n",
    "\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([model1.output, input_ICN])\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "\n",
    "    z = Dense(fc_nodes, activation='relu')(combined)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Dense(1, activation='relu')(z)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = keras.Model(inputs=input_all, outputs=z)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# create model\n",
    "model_LSTM = KerasRegressor(build_fn=create_model)\n",
    "# define the grid search parameters\n",
    "# layer1_units = [16, 32, 64, 128]\n",
    "# layer2_units=[3, 4, 5, 6]\n",
    "# dropout_rate1=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# dropout_rate2=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "filters = [10, 20, 50]\n",
    "kernel_size = [2, 3, 4, 5]\n",
    "LSTM_units=[2, 4, 8]\n",
    "dropout_rate1=[0.0, 0.1, 0.2]\n",
    "fc_nodes=[6, 14, 64]\n",
    "param_grid = dict(filters=filters, kernel_size=kernel_size, LSTM_units=LSTM_units, dropout_rate1=dropout_rate1, fc_nodes=fc_nodes)\n",
    "LSTM_search = GridSearchCV(estimator=model_LSTM, param_grid=param_grid, cv=10, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## merge inputs\n",
    "combine_input_train = np.concatenate([np.reshape(X_train_channel, [np.shape(X_train_channel)[0], -1]), ICN_train], axis=1)\n",
    "combine_input_test = np.concatenate([np.reshape(X_test_channel, [np.shape(X_test_channel)[0], -1]), ICN_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search to find the best model ï¼ˆThis steps takes a long time to run)\n",
    "tf.keras.utils.set_random_seed(2)\n",
    "best_model = LSTM_search.fit(combine_input_train, Y_train,  batch_size=batch_size,  epochs=1200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Hyperparameters: %s' % best_model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the gbrt with the best combination of hyperparameters\n",
    "#large max_depth to prevent overfitting\n",
    "model_LSTM_best = KerasRegressor(build_fn=create_model, filters=64, LSTM_units=3, dropout_rate1=0.2, fc_nodes=50)\n",
    "model_LSTM_best.fit(combine_input_train, Y_train, batch_size=batch_size,  epochs=1200, verbose=1)\n",
    "pred_train = model_LSTM_best.predict(combine_input_train)*max_y\n",
    "pred_test = model_LSTM_best.predict(combine_input_test)*max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test*max_y, pred_test))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test*max_y, pred_test))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test*max_y, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_list=['Nalm 6 Cytotoxicity','IL7RaKLRG1 stemness']\n",
    "def do_plot(ax_row, pred_train, pred_test):\n",
    "    i=0\n",
    "    gt=Y_train*max_y\n",
    "    ax_row[0].scatter(gt,pred_train)\n",
    "    xmin=min(min(gt),min(pred_train))\n",
    "    xmax=max(max(gt),max(pred_train))\n",
    "    xline=np.linspace(xmin,xmax,10)\n",
    "    ax_row[0].plot(xline,xline,color='red')\n",
    "    ax_row[0].set_xlabel('Ground Truth (Training)')\n",
    "    ax_row[0].set_ylabel('Predictions (Training)')\n",
    "    correlation_matrix = np.corrcoef(gt, pred_train)\n",
    "    corr = correlation_matrix[0,1]\n",
    "    r_squared_train = corr**2\n",
    "    ax_row[0].set_title(title_list[i]+'\\n'+'R^2='+str(r_squared_train)[:5])\n",
    "    ax_row[0].axis('square')\n",
    "\n",
    "    gt=Y_test*max_y\n",
    "    ax_row[1].scatter(gt,pred_test)\n",
    "    xmin=min(min(gt),min(pred_test))\n",
    "    xmax=max(max(gt),max(pred_test))\n",
    "    xline=np.linspace(xmin,xmax,10)\n",
    "    ax_row[1].plot(xline,xline,color='red')\n",
    "    ax_row[1].set_xlabel('Ground Truth (Test)', fontsize=20)\n",
    "    ax_row[1].set_ylabel('Predictions (Test)', fontsize=20)\n",
    "    correlation_matrix = np.corrcoef(gt, pred_test)\n",
    "    corr = correlation_matrix[0,1]\n",
    "    r_squared_test = corr**2\n",
    "    ax_row[1].set_title(title_list[i]+'\\n'+'R^2='+str(r_squared_test)[:5])\n",
    "    plt.axis('square')\n",
    "    \n",
    "    return r_squared_train, r_squared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=[15,70])\n",
    "do_plot(axs, pred_train, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models using hyperparameters in supplementary materials\n",
    "### See Table S1 of https://www.science.org/doi/suppl/10.1126/science.abq0225/suppl_file/science.abq0225_sm.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_set = [\n",
    "    [20, 5, 4, 0., 64, ],\n",
    "    [10, 2, 8, 0., 16, ],\n",
    "    [20, 4, 8, 0.2, 4, ],\n",
    "    [10, 2, 4, 0., 64, ],\n",
    "    [20, 4, 2, 0., 16, ],\n",
    "    [20, 2, 4, 0., 4, ],\n",
    "    [10, 5, 4, 0., 16, ],\n",
    "    [20, 5, 4, 0., 4, ],\n",
    "    [20, 2, 4, 0., 4, ],\n",
    "    [50, 5, 4, 0., 4, ],\n",
    "]\n",
    "tf.keras.utils.set_random_seed(3)\n",
    "fig, axs = plt.subplots(len(hyperparameter_set), 2, figsize=[15,70])\n",
    "for i, (filters, kernel_size, LSTM_units, dropout_rate, fc_nodes) in enumerate(hyperparameter_set):\n",
    "    # Rerun the gbrt with the best combination of hyperparameters\n",
    "    #large max_depth to prevent overfitting\n",
    "    model_LSTM_best = KerasRegressor(build_fn=create_model, filters=filters, LSTM_units=LSTM_units, dropout_rate1=dropout_rate, fc_nodes=fc_nodes)\n",
    "    model_LSTM_best.fit(combine_input_train, Y_train, batch_size=batch_size,  epochs=1200, verbose=0)\n",
    "    pred_train = model_LSTM_best.predict(combine_input_train)*max_y\n",
    "    pred_test = model_LSTM_best.predict(combine_input_test)*max_y\n",
    "    r_squared_train, r_squared_test = do_plot(axs[i], pred_train, pred_test)\n",
    "    print(i+1, filters, kernel_size, LSTM_units, dropout_rate, fc_nodes, '{:.3f}'.format(r_squared_train), '{:.3f}'.format(r_squared_test))\n",
    "    model_LSTM_best.model.save(f'saved_model/position_encoding_arrayed_data_04062023_CNN_LSTM_Cytotoxicity_{i+1}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
